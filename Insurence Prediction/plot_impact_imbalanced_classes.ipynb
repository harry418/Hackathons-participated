{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "plot_impact_imbalanced_classes.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harry418/Hackathons-participated/blob/main/Insurence%20Prediction/plot_impact_imbalanced_classes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J2aY99EdKUB"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZHz9kk0dKUI"
      },
      "source": [
        "\n",
        "# Fitting model on imbalanced datasets and how to fight bias\n",
        "\n",
        "\n",
        "This example illustrates the problem induced by learning on datasets having\n",
        "imbalanced classes. Subsequently, we compare different approaches alleviating\n",
        "these negative effects.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy3RQ9x0dKUJ",
        "outputId": "f30314d3-1f23-4b5e-c756-2b88b0248a9c"
      },
      "source": [
        "# Authors: Guillaume Lemaitre <g.lemaitre58@gmail.com>\n",
        "# License: MIT\n",
        "\n",
        "print(__doc__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Automatically created module for IPython interactive environment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dovR8iiodUWd",
        "outputId": "bd6cb049-0a77-458a-c288-de381c309dcc"
      },
      "source": [
        "!wget -O \"learn_ml_insurance_prediction__ai_challenge-dataset.zip\" \"https://dockship-job-models.s3.ap-south-1.amazonaws.com/196c328ad298ef1476f56437902688ef?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIDOPTEUZ2LEOQEGQ%2F20210120%2Fap-south-1%2Fs3%2Faws4_request&X-Amz-Date=20210120T062225Z&X-Amz-Expires=1800&X-Amz-Signature=87efa5328b5dfba3f163cca5118a43ea47a9a54eb400cc4844db81c4889665ef&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D%22learn_ml_insurance_prediction__ai_challenge-dataset.zip%22\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-20 06:22:32--  https://dockship-job-models.s3.ap-south-1.amazonaws.com/196c328ad298ef1476f56437902688ef?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIDOPTEUZ2LEOQEGQ%2F20210120%2Fap-south-1%2Fs3%2Faws4_request&X-Amz-Date=20210120T062225Z&X-Amz-Expires=1800&X-Amz-Signature=87efa5328b5dfba3f163cca5118a43ea47a9a54eb400cc4844db81c4889665ef&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D%22learn_ml_insurance_prediction__ai_challenge-dataset.zip%22\n",
            "Resolving dockship-job-models.s3.ap-south-1.amazonaws.com (dockship-job-models.s3.ap-south-1.amazonaws.com)... 52.219.62.7\n",
            "Connecting to dockship-job-models.s3.ap-south-1.amazonaws.com (dockship-job-models.s3.ap-south-1.amazonaws.com)|52.219.62.7|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5149099 (4.9M) [binary/octet-stream]\n",
            "Saving to: ‘learn_ml_insurance_prediction__ai_challenge-dataset.zip’\n",
            "\n",
            "learn_ml_insurance_ 100%[===================>]   4.91M  2.86MB/s    in 1.7s    \n",
            "\n",
            "2021-01-20 06:22:35 (2.86 MB/s) - ‘learn_ml_insurance_prediction__ai_challenge-dataset.zip’ saved [5149099/5149099]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjWW3t7zdYAC",
        "outputId": "39ed5d9d-6806-4486-dba8-d3170b1ee9fa"
      },
      "source": [
        "! unzip \"learn_ml_insurance_prediction__ai_challenge-dataset.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  learn_ml_insurance_prediction__ai_challenge-dataset.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: TEST.csv                \n",
            "  inflating: TRAIN.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3tydHj_d3RC"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv(\"/content/TRAIN.csv\")\n",
        "test = pd.read_csv(\"/content/TEST.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuwjmZZeeBed"
      },
      "source": [
        "df_res = train.drop(['id','Response'], axis=1)\n",
        "y_res = train['Response'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la1SauKedKUJ"
      },
      "source": [
        "Problem definition\n",
        "##############################################################################\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppNvRUbhdKUK"
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "df, y = fetch_openml('adult', version=2, as_frame=True, return_X_y=True)\n",
        "# we are dropping the following features:\n",
        "# - \"fnlwgt\": this feature was created while studying the \"adult\" dataset.\n",
        "#   Thus, we will not use this feature which is not acquired during the survey.\n",
        "# - \"education-num\": it is encoding the same information than \"education\".\n",
        "#   Thus, we are removing one of these 2 features.\n",
        "df = df.drop(columns=['fnlwgt', 'education-num'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3S1zaTgdKUK"
      },
      "source": [
        "The \"adult\" dataset as a class ratio of about 3:1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qF-JzFMAdKUK"
      },
      "source": [
        "classes_count = y.value_counts()\n",
        "classes_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaYeIXY4dKUL"
      },
      "source": [
        "This dataset is only slightly imbalanced. To better highlight the effect of\n",
        "learning from an imbalanced dataset, we will increase its ratio to 30:1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk4d8dAXdKUL"
      },
      "source": [
        "from imblearn.datasets import make_imbalance\n",
        "\n",
        "ratio = 30\n",
        "df_res, y_res = make_imbalance(\n",
        "    df, y, sampling_strategy={\n",
        "        classes_count.idxmin(): classes_count.max() // ratio\n",
        "    }\n",
        ")\n",
        "y_res.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9v5yQi_dKUL"
      },
      "source": [
        "For the rest of the notebook, we will make a single split to get training\n",
        "and testing data. Note that you should use cross-validation to have an\n",
        "estimate of the performance variation in practice.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cahJewYJdKUM"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df_res, y_res, stratify=y_res, random_state=42\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HGG8MOJdKUM"
      },
      "source": [
        "As a baseline, we could use a classifier which will always predict the\n",
        "majority class independently of the features provided.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW4gaWrqdKUM",
        "outputId": "b3e7ece2-59fe-43eb-dc7b-bf2fbb34f3b3"
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
        "score = dummy_clf.fit(X_train, y_train).score(X_test, y_test)\n",
        "print(f\"Accuracy score of a dummy classifier: {score:.3f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score of a dummy classifier: 0.878\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaJkYjzudKUN"
      },
      "source": [
        "Instead of using the accuracy, we can use the balanced accuracy which will\n",
        "take into account the balancing issue.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tRn8JSpdKUN",
        "outputId": "234e39bf-fbc4-45b6-9c70-256054728e8e"
      },
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "y_pred = dummy_clf.predict(X_test)\n",
        "score = balanced_accuracy_score(y_test, y_pred)\n",
        "print(f\"Balanced accuracy score of a dummy classifier: {score:.3f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Balanced accuracy score of a dummy classifier: 0.500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3FkxhsYdKUN"
      },
      "source": [
        "Strategies to learn from an imbalanced dataset\n",
        "##############################################################################\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yG_ifm_LdKUN"
      },
      "source": [
        "We will first define a helper function which will train a given model\n",
        "and compute both accuracy and balanced accuracy. The results will be stored\n",
        "in a dataframe\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOjxMlJbdKUN"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def evaluate_classifier(clf, df_scores, clf_name=None):\n",
        "    from sklearn.pipeline import Pipeline\n",
        "    if clf_name is None:\n",
        "        if isinstance(clf, Pipeline):\n",
        "            clf_name = clf[-1].__class__.__name__\n",
        "        else:\n",
        "            clf_name = clf.__class__.__name__\n",
        "    acc = clf.fit(X_train, y_train).score(X_test, y_test)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "    clf_score = pd.DataFrame(\n",
        "        {clf_name: [acc, bal_acc]},\n",
        "        index=['Accuracy', 'Balanced accuracy']\n",
        "    )\n",
        "    df_scores = pd.concat([df_scores, clf_score], axis=1).round(decimals=3)\n",
        "    return df_scores\n",
        "\n",
        "\n",
        "# Let's define an empty dataframe to store the results\n",
        "df_scores = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW08HKJxdKUO"
      },
      "source": [
        "Dummy baseline\n",
        "..............\n",
        "\n",
        "Before to train a real machine learning model, we can store the results\n",
        "obtained with our `DummyClassifier`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "OedbbBsedKUO",
        "outputId": "2c506528-1698-48fe-a071-d01001679cd1"
      },
      "source": [
        "df_scores = evaluate_classifier(dummy_clf, df_scores, \"Dummy\")\n",
        "df_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dummy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy</th>\n",
              "      <td>0.878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Balanced accuracy</th>\n",
              "      <td>0.500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Dummy\n",
              "Accuracy           0.878\n",
              "Balanced accuracy  0.500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctMUKI-edKUO"
      },
      "source": [
        "Linear classifier baseline\n",
        "..........................\n",
        "\n",
        "We will create a machine learning pipeline using a `LogisticRegression`\n",
        "classifier. In this regard, we will need to one-hot encode the categorical\n",
        "columns and standardized the numerical columns before to inject the data into\n",
        "the `LogisticRegression` classifier.\n",
        "\n",
        "First, we define our numerical and categorical pipelines.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THbG71NcdKUP"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "num_pipe = make_pipeline(\n",
        "    StandardScaler(), SimpleImputer(strategy=\"mean\", add_indicator=True)\n",
        ")\n",
        "cat_pipe = make_pipeline(\n",
        "    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
        "    OneHotEncoder(handle_unknown=\"ignore\")\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA_jsBv_dKUP"
      },
      "source": [
        "Then, we can create a preprocessor which will dispatch the categorical\n",
        "columns to the categorical pipeline and the numerical columns to the\n",
        "numerical pipeline\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keRx0dtsdKUP"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.compose import make_column_selector as selector\n",
        "\n",
        "preprocessor_linear = ColumnTransformer(\n",
        "    [(\"num-pipe\", num_pipe, selector(dtype_include=np.number)),\n",
        "     (\"cat-pipe\", cat_pipe, selector(dtype_include=pd.CategoricalDtype))],\n",
        "    n_jobs=2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JPBBdlXdKUP"
      },
      "source": [
        "Finally, we connect our preprocessor with our `LogisticRegression`. We can\n",
        "then evaluate our model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "3KUcEpjPdKUQ",
        "outputId": "483fa204-99b2-4b3a-c9a7-1296e1314089"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_clf = make_pipeline(\n",
        "    preprocessor_linear, LogisticRegression(max_iter=1000)\n",
        ")\n",
        "df_scores = evaluate_classifier(lr_clf, df_scores, \"LR\")\n",
        "df_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dummy</th>\n",
              "      <th>LR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy</th>\n",
              "      <td>0.878</td>\n",
              "      <td>0.878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Balanced accuracy</th>\n",
              "      <td>0.500</td>\n",
              "      <td>0.500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Dummy     LR\n",
              "Accuracy           0.878  0.878\n",
              "Balanced accuracy  0.500  0.500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjwyX_E6dKUQ"
      },
      "source": [
        "We can see that our linear model is learning slightly better than our dummy\n",
        "baseline. However, it is impacted by the class imbalance.\n",
        "\n",
        "We can verify that something similar is happening with a tree-based model\n",
        "such as `RandomForestClassifier`. With this type of classifier, we will not\n",
        "need to scale the numerical data, and we will only need to ordinal encode the\n",
        "categorical data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "8NHF8GxFdKUQ",
        "outputId": "56d2c2ab-663a-4d05-9e67-73c10be2f717"
      },
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "cat_pipe = make_pipeline(\n",
        "    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
        "    OrdinalEncoder()\n",
        ")\n",
        "\n",
        "preprocessor_tree = ColumnTransformer(\n",
        "    [(\"num-pipe\", num_pipe, selector(dtype_include=np.number)),\n",
        "     (\"cat-pipe\", cat_pipe, selector(dtype_include=pd.CategoricalDtype))],\n",
        "    n_jobs=2\n",
        ")\n",
        "\n",
        "rf_clf = make_pipeline(\n",
        "    preprocessor_tree, RandomForestClassifier(random_state=42, n_jobs=2)\n",
        ")\n",
        "\n",
        "df_scores = evaluate_classifier(rf_clf, df_scores, \"RF\")\n",
        "df_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dummy</th>\n",
              "      <th>LR</th>\n",
              "      <th>RF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy</th>\n",
              "      <td>0.878</td>\n",
              "      <td>0.878</td>\n",
              "      <td>0.866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Balanced accuracy</th>\n",
              "      <td>0.500</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.536</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Dummy     LR     RF\n",
              "Accuracy           0.878  0.878  0.866\n",
              "Balanced accuracy  0.500  0.500  0.536"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVk3IDIXdKUR"
      },
      "source": [
        "The `RandomForestClassifier` is as well affected by the class imbalanced,\n",
        "slightly less than the linear model. Now, we will present different approach\n",
        "to improve the performance of these 2 models.\n",
        "\n",
        "Use `class_weight`\n",
        "..................\n",
        "\n",
        "Most of the models in `scikit-learn` have a parameter `class_weight`. This\n",
        "parameter will affect the computation of the loss in linear model or the\n",
        "criterion in the tree-based model to penalize differently a false\n",
        "classification from the minority and majority class. We can set\n",
        "`class_weight=\"balanced\"` such that the weight applied is inversely\n",
        "proportional to the class frequency. We test this parametrization in both\n",
        "linear model and tree-based model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "Nvl9txZBdKUR",
        "outputId": "87ca4c78-f3a7-4398-d502-b1523a1507fb"
      },
      "source": [
        "lr_clf.set_params(logisticregression__class_weight=\"balanced\")\n",
        "df_scores = evaluate_classifier(\n",
        "    lr_clf, df_scores, \"LR with class weight\"\n",
        ")\n",
        "df_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dummy</th>\n",
              "      <th>LR</th>\n",
              "      <th>RF</th>\n",
              "      <th>LR with class weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy</th>\n",
              "      <td>0.878</td>\n",
              "      <td>0.878</td>\n",
              "      <td>0.866</td>\n",
              "      <td>0.580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Balanced accuracy</th>\n",
              "      <td>0.500</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.536</td>\n",
              "      <td>0.759</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Dummy     LR     RF  LR with class weight\n",
              "Accuracy           0.878  0.878  0.866                 0.580\n",
              "Balanced accuracy  0.500  0.500  0.536                 0.759"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "eEnITQZgdKUR",
        "outputId": "1c105ebc-acd9-44f1-df2a-baf7ff32c058"
      },
      "source": [
        "rf_clf.set_params(randomforestclassifier__class_weight=\"balanced\")\n",
        "df_scores = evaluate_classifier(\n",
        "    rf_clf, df_scores, \"RF with class weight\"\n",
        ")\n",
        "df_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dummy</th>\n",
              "      <th>LR</th>\n",
              "      <th>RF</th>\n",
              "      <th>LR with class weight</th>\n",
              "      <th>RF with class weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy</th>\n",
              "      <td>0.878</td>\n",
              "      <td>0.878</td>\n",
              "      <td>0.866</td>\n",
              "      <td>0.580</td>\n",
              "      <td>0.867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Balanced accuracy</th>\n",
              "      <td>0.500</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.536</td>\n",
              "      <td>0.759</td>\n",
              "      <td>0.531</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Dummy     LR  ...  LR with class weight  RF with class weight\n",
              "Accuracy           0.878  0.878  ...                 0.580                 0.867\n",
              "Balanced accuracy  0.500  0.500  ...                 0.759                 0.531\n",
              "\n",
              "[2 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUCSjs9CdKUS"
      },
      "source": [
        "We can see that using `class_weight` was really effective for the linear\n",
        "model, alleviating the issue of learning from imbalanced classes. However,\n",
        "the `RandomForestClassifier` is still biased toward the majority class,\n",
        "mainly due to the criterion which is not suited enough to fight the class\n",
        "imbalance.\n",
        "\n",
        "Resample the training set during learning\n",
        ".........................................\n",
        "\n",
        "Another way is to resample the training set by under-sampling or\n",
        "over-sampling some of the samples. `imbalanced-learn` provides some samplers\n",
        "to do such processing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "Yxa03U-edKUS",
        "outputId": "9a7aec5d-73af-46a1-c216-380f4f157798"
      },
      "source": [
        "from imblearn.pipeline import make_pipeline as make_pipeline_with_sampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "lr_clf = make_pipeline_with_sampler(\n",
        "    preprocessor_linear,\n",
        "    RandomUnderSampler(random_state=42),\n",
        "    LogisticRegression(max_iter=1000)\n",
        ")\n",
        "df_scores = evaluate_classifier(\n",
        "    lr_clf, df_scores, \"LR with under-sampling\"\n",
        ")\n",
        "df_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dummy</th>\n",
              "      <th>LR</th>\n",
              "      <th>RF</th>\n",
              "      <th>LR with class weight</th>\n",
              "      <th>RF with class weight</th>\n",
              "      <th>LR with under-sampling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy</th>\n",
              "      <td>0.878</td>\n",
              "      <td>0.878</td>\n",
              "      <td>0.866</td>\n",
              "      <td>0.580</td>\n",
              "      <td>0.867</td>\n",
              "      <td>0.580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Balanced accuracy</th>\n",
              "      <td>0.500</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.536</td>\n",
              "      <td>0.759</td>\n",
              "      <td>0.531</td>\n",
              "      <td>0.759</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Dummy     LR  ...  RF with class weight  LR with under-sampling\n",
              "Accuracy           0.878  0.878  ...                 0.867                   0.580\n",
              "Balanced accuracy  0.500  0.500  ...                 0.531                   0.759\n",
              "\n",
              "[2 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "tS93fuD4dKUS",
        "outputId": "d4dc582b-14be-487a-f11e-8901840382aa"
      },
      "source": [
        "rf_clf = make_pipeline_with_sampler(\n",
        "    preprocessor_tree,\n",
        "    RandomUnderSampler(random_state=42),\n",
        "    RandomForestClassifier(random_state=42, n_jobs=2)\n",
        ")\n",
        "\n",
        "df_scores = evaluate_classifier(\n",
        "    rf_clf, df_scores, \"RF with under-sampling\"\n",
        ")\n",
        "df_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dummy</th>\n",
              "      <th>LR</th>\n",
              "      <th>RF</th>\n",
              "      <th>LR with class weight</th>\n",
              "      <th>RF with class weight</th>\n",
              "      <th>LR with under-sampling</th>\n",
              "      <th>RF with under-sampling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy</th>\n",
              "      <td>0.878</td>\n",
              "      <td>0.878</td>\n",
              "      <td>0.866</td>\n",
              "      <td>0.580</td>\n",
              "      <td>0.867</td>\n",
              "      <td>0.580</td>\n",
              "      <td>0.691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Balanced accuracy</th>\n",
              "      <td>0.500</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.536</td>\n",
              "      <td>0.759</td>\n",
              "      <td>0.531</td>\n",
              "      <td>0.759</td>\n",
              "      <td>0.767</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Dummy     LR  ...  LR with under-sampling  RF with under-sampling\n",
              "Accuracy           0.878  0.878  ...                   0.580                   0.691\n",
              "Balanced accuracy  0.500  0.500  ...                   0.759                   0.767\n",
              "\n",
              "[2 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZldB6RKdKUS"
      },
      "source": [
        "Applying a random under-sampler before the training of the linear model or\n",
        "random forest, allows to not focus on the majority class at the cost of\n",
        "making more mistake for samples in the majority class (i.e. decreased\n",
        "accuracy).\n",
        "\n",
        "We could apply any type of samplers and find which sampler is working best\n",
        "on the current dataset.\n",
        "\n",
        "Instead, we will present another way by using classifiers which will apply\n",
        "sampling internally.\n",
        "\n",
        "Use of `BalancedRandomForestClassifier` and `BalancedBaggingClassifier`\n",
        ".......................................................................\n",
        "\n",
        "We already showed that random under-sampling can be effective on decision\n",
        "tree. However, instead of under-sampling once the dataset, one could\n",
        "under-sample the original dataset before to take a bootstrap sample. This is\n",
        "the base of the `BalancedRandomForestClassifier` and\n",
        "`BalancedBaggingClassifier`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcYcEE3RdKUT"
      },
      "source": [
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "\n",
        "rf_clf = make_pipeline(\n",
        "    preprocessor_tree,\n",
        "    BalancedRandomForestClassifier(random_state=42, n_jobs=2)\n",
        ")\n",
        "\n",
        "df_scores = evaluate_classifier(rf_clf, df_scores, \"Balanced RF\")\n",
        "df_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7qKDomidKUT"
      },
      "source": [
        "The performance with the `BalancedRandomForestClassifier` is better than\n",
        "applying a single random under-sampling. We will use a gradient-boosting\n",
        "classifier within a `BalancedBaggingClassifier`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "rmDFP6kkdKUU",
        "outputId": "b995c7d3-c33e-48fa-fd77-549c4b69499f"
      },
      "source": [
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from imblearn.ensemble import BalancedBaggingClassifier\n",
        "\n",
        "bag_clf = make_pipeline(\n",
        "    preprocessor_tree,\n",
        "    BalancedBaggingClassifier(\n",
        "        base_estimator=HistGradientBoostingClassifier(random_state=42),\n",
        "        n_estimators=10, random_state=42, n_jobs=2\n",
        "    )\n",
        ")\n",
        "\n",
        "df_scores = evaluate_classifier(\n",
        "    bag_clf, df_scores, \"Balanced bagging\"\n",
        ")\n",
        "df_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dummy</th>\n",
              "      <th>LR</th>\n",
              "      <th>RF</th>\n",
              "      <th>LR with class weight</th>\n",
              "      <th>RF with class weight</th>\n",
              "      <th>LR with under-sampling</th>\n",
              "      <th>RF with under-sampling</th>\n",
              "      <th>Balanced bagging</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy</th>\n",
              "      <td>0.878</td>\n",
              "      <td>0.878</td>\n",
              "      <td>0.866</td>\n",
              "      <td>0.580</td>\n",
              "      <td>0.867</td>\n",
              "      <td>0.580</td>\n",
              "      <td>0.691</td>\n",
              "      <td>0.686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Balanced accuracy</th>\n",
              "      <td>0.500</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.536</td>\n",
              "      <td>0.759</td>\n",
              "      <td>0.531</td>\n",
              "      <td>0.759</td>\n",
              "      <td>0.767</td>\n",
              "      <td>0.787</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Dummy     LR  ...  RF with under-sampling  Balanced bagging\n",
              "Accuracy           0.878  0.878  ...                   0.691             0.686\n",
              "Balanced accuracy  0.500  0.500  ...                   0.767             0.787\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGn4n6RSdKUU"
      },
      "source": [
        "This last approach is the most effective. The different under-sampling allows\n",
        "to bring some diversity for the different GBDT to learn and not focus on a\n",
        "portion of the majority class.\n",
        "\n",
        "We will repeat the same experiment but with a ratio of 100:1 and make a\n",
        "similar analysis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5rHr-o6dKUU"
      },
      "source": [
        "Increase imbalanced ratio\n",
        "##############################################################################\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6fBjPckdKUU"
      },
      "source": [
        "ratio = 100\n",
        "df_res, y_res = make_imbalance(\n",
        "    df, y, sampling_strategy={\n",
        "        classes_count.idxmin(): classes_count.max() // ratio\n",
        "    }\n",
        ")\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df_res, y_res, stratify=y_res, random_state=42\n",
        ")\n",
        "\n",
        "df_scores = pd.DataFrame()\n",
        "df_scores = evaluate_classifier(dummy_clf, df_scores, \"Dummy\")\n",
        "lr_clf = make_pipeline(\n",
        "    preprocessor_linear, LogisticRegression(max_iter=1000)\n",
        ")\n",
        "df_scores = evaluate_classifier(lr_clf, df_scores, \"LR\")\n",
        "rf_clf = make_pipeline(\n",
        "    preprocessor_tree, RandomForestClassifier(random_state=42, n_jobs=2)\n",
        ")\n",
        "df_scores = evaluate_classifier(rf_clf, df_scores, \"RF\")\n",
        "lr_clf.set_params(logisticregression__class_weight=\"balanced\")\n",
        "df_scores = evaluate_classifier(\n",
        "    lr_clf, df_scores, \"LR with class weight\"\n",
        ")\n",
        "rf_clf.set_params(randomforestclassifier__class_weight=\"balanced\")\n",
        "df_scores = evaluate_classifier(\n",
        "    rf_clf, df_scores, \"RF with class weight\"\n",
        ")\n",
        "lr_clf = make_pipeline_with_sampler(\n",
        "    preprocessor_linear,\n",
        "    RandomUnderSampler(random_state=42),\n",
        "    LogisticRegression(max_iter=1000)\n",
        ")\n",
        "df_scores = evaluate_classifier(\n",
        "    lr_clf, df_scores, \"LR with under-sampling\"\n",
        ")\n",
        "rf_clf = make_pipeline_with_sampler(\n",
        "    preprocessor_tree,\n",
        "    RandomUnderSampler(random_state=42),\n",
        "    RandomForestClassifier(random_state=42, n_jobs=2)\n",
        ")\n",
        "df_scores = evaluate_classifier(\n",
        "    rf_clf, df_scores, \"RF with under-sampling\"\n",
        ")\n",
        "rf_clf = make_pipeline(\n",
        "    preprocessor_tree,\n",
        "    BalancedRandomForestClassifier(random_state=42, n_jobs=2)\n",
        ")\n",
        "df_scores = evaluate_classifier(rf_clf, df_scores)\n",
        "df_scores = evaluate_classifier(\n",
        "    bag_clf, df_scores, \"Balanced bagging\"\n",
        ")\n",
        "df_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BvDS5F4dKUV"
      },
      "source": [
        "When we analyse the results, we can draw similar conclusions than in the\n",
        "previous discussion. However, we can observe that the strategy\n",
        "`class_weight=\"balanced\"` does not improve the performance when using a\n",
        "`RandomForestClassifier`. A resampling is indeed required. The most effective\n",
        "method remains the `BalancedBaggingClassifier` using a GBDT as a base\n",
        "learner.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pDbdbVLkMTD",
        "outputId": "1426466c-d9fe-4f37-c6ec-09783ff5def1"
      },
      "source": [
        "from sklearn.datasets import make_moons, make_blobs\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from imblearn import FunctionSampler\n",
        "from imblearn.pipeline import make_pipeline\n",
        "\n",
        "print(__doc__)\n",
        "\n",
        "rng = np.random.RandomState(42)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Automatically created module for IPython interactive environment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HmJF4KZkyM_"
      },
      "source": [
        "X = df_res\n",
        "y = y_res\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# fit the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doyH50phkPOa"
      },
      "source": [
        "def outlier_rejection(X, y):\n",
        "    \"\"\"This will be our function used to resample our dataset.\"\"\"\n",
        "    model = IsolationForest(max_samples=100,\n",
        "                            contamination=0.4,\n",
        "                            random_state=rng)\n",
        "    model.fit(X)\n",
        "    y_pred = model.predict(X)\n",
        "    return X[y_pred == 1], y[y_pred == 1]\n",
        "reject_sampler = FunctionSampler(func=outlier_rejection)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBeiKkBakaA7"
      },
      "source": [
        "\n",
        "pipe = make_pipeline(FunctionSampler(func=outlier_rejection),\n",
        "                     LogisticRegression(solver='lbfgs', multi_class='auto',\n",
        "                                        random_state=rng))\n",
        "y_pred = pipe.fit(X_train, y_train).predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "clf = LogisticRegression(solver='lbfgs', multi_class='auto', random_state=rng)\n",
        "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}